\documentclass[aspectratio=169]{../latex_main/tntbeamer}  % you can pass all options of the beamer class, e.g., 'handout' or 'aspectratio=43'
\input{../latex_main/preamble}

\title[DL in a Nutshell]{DS: Deep Learning}
\subtitle{DL in a Nutshell}

\date{\hspace{0.5em} {\includegraphics[height=1.5em]{../latex_main/figures/Cc-by-nc-sa_icon.svg.png}}}

\graphicspath{ {./figure/} }
%\institute{}


\begin{document}
	
	\maketitle
	\begin{frame}{MLP Definition (Recap)}

        Recursive definition of MLPs:

            \[
            \hat{\textbf{y}}^{(l)} = \sigma(\textbf{W}^{(l)} \hat{\textbf{y}}^{(l-1)} + \textbf{b}^{(l)})
            \]
            
            where:
            \begin{itemize}
                \item \( \hat{\textbf{y}}^{(l)} \) is the output vector from layer \( l \)
                \item \( \textbf{W}^{(l)} \) represents the weight matrix for layer \( l \)
                \item \( \hat{\textbf{y}}^{(l-1)} \) is the output vector from the previous layer \( l-1 \)
                \item \( \textbf{b}^{(l)} \) is the bias vector for layer \( l \)
                \item \( \sigma \) is the activation function (e.g., ReLU)
            \end{itemize}
                
	\end{frame}

        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  	\begin{frame}{Forward Propagation}

        \includegraphics[width=0.8\textwidth]{figures/forward.png}

        \end{frame}

        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  	\begin{frame}{Forward Propagation}

        \begin{itemize}
            \item The process of calculating the output from the input layer through to the output layer.
            \item Inputs are processed at each layer using weights, biases, and an activation function.
        \end{itemize}

        
        \begin{block}{Steps of Forward Propagation}
        \begin{enumerate}
            \item Start with the input layer \( \hat{\textbf{y}}^{(0)} = \textbf{x} \), where \( \textbf{x} \) is the input vector.
            \item For each layer from 1 to \( L \) (where \( L \) is the output layer):
                \begin{itemize}
                    \item Compute the pre-activation \( \textbf{z}^{(l)} = \textbf{W}^{(l)} \hat{\textbf{y}}^{(l-1)} + \textbf{b}^{(l)} \)
                    \item Apply the activation function \( \hat{\textbf{y}}^{(l)} = \sigma(\textbf{z}^{(l)}) \)
                \end{itemize}
            \item The final output \( \hat{\textbf{y}}^{(L)} \) is the prediction of the network.
        \end{enumerate}
        \end{block}
                
	  \end{frame}

        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  	\begin{frame}{Backpropagation: I}

        \vspace{-2em}
        \begin{itemize}
            \item Backpropagation is used to calculate the gradient of the loss function of a DNN wrt its weights.
            \item Key algorithm used in training DNN, allowing for efficient computation of gradients.
        \end{itemize}
        
        \begin{block}{Error Term Calculation}
        For each output neuron \( k \), the error \( \delta_k \) is computed as:
        \[
        \delta_k = \frac{\partial \mathcal{L}}{\partial \hat{y}_k^{(L)}} \sigma'(z_k^{(L)})
        \]
        where:
        \begin{itemize}
            \item \( \mathcal{L} \) is the loss function.
            \item \( \hat{y}_k^{(L)} \) is the activation of the \( k \)-th neuron in the output layer.
            \item \( \sigma' \) is the derivative of the activation function.
            \item \( z_k^{(L)} \) is the input to the activation function in the output layer.
        \end{itemize}
        \end{block}

        \end{frame}
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  	\begin{frame}{Backpropagation: II}

        \includegraphics[width=0.8\textwidth]{figures/backward.png}

        \end{frame}
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \begin{frame}{Backpropagation: III}

        \vspace{-2em}
        \begin{block}{Gradient Computation for Weights}
        The gradient of the loss with respect to the weights is given by:
        \[
        \frac{\partial \mathcal{L}}{\partial w_{ij}^{(l)}} = \hat{y}_j^{(l-1)} \delta_i^{(l)}
        \]
        where:
        \begin{itemize}
            \item \( w_{ij}^{(l)} \) are the weights connecting neuron \( j \) in layer \( l-1 \) to neuron \( i \) in layer \( l \).
            \item \( \delta_i^{(l)} \) is the error term for neuron \( i \) in layer \( l \).
        \end{itemize}
        \end{block}

        Important to note: Backpropagation makes use of the chain rule of calculus
        
        \end{frame}
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \begin{frame}{Update Rule}

        \begin{block}{Update Rule}
            Weights are updated using the rule:
            \[
            w_{ij}^{(l)} \leftarrow w_{ij}^{(l)} - \eta \frac{\partial \mathcal{L}}{\partial w_{ij}^{(l)}}
            \]
            where \( \eta \) is the learning rate.
         \end{block}
            
        \end{frame}

        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        \begin{frame}{The Chain Rule in Backpropagation (Optional Slide)}

        \vspace{-2em}
        \begin{itemize}
            \item The chain rule of calculus is essential for understanding how gradients are computed in backpropagation.
            \item Backpropagation uses the chain rule to find the derivatives of the loss function with respect to each weight in the network by propagating errors back from the output towards the input layer.
        \end{itemize}
        
        \begin{itemize}
            \item To update the weight \( w_{ij}^{(l)} \), we need to compute:\\
            $
            \frac{\partial \mathcal{L}}{\partial w_{ij}^{(l)}} = \frac{\partial \mathcal{L}}{\partial \hat{y}_i^{(l)}} \cdot \frac{\partial \hat{y}_i^{(l)}}{\partial z_i^{(l)}} \cdot \frac{\partial z_i^{(l)}}{\partial w_{ij}^{(l)}}
            $
            \item Where:
            \begin{itemize}
                \item \( \frac{\partial \mathcal{L}}{\partial \hat{y}_i^{(l)}} \) is the derivative of the loss function with respect to the activation of neuron \( i \) in layer \( l \).
                \item \( \frac{\partial \hat{y}_i^{(l)}}{\partial z_i^{(l)}} \) is the derivative of the activation function at \( z_i^{(l)} \).
                \item \( \frac{\partial z_i^{(l)}}{\partial w_{ij}^{(l)}} \) is the input from neuron \( j \) in the previous layer \( l-1 \).
            \end{itemize}
            \item This decomposition illustrates the chain rule's role in determining how changes in weights affect the loss function.
        \end{itemize}
        
        % \begin{block}{Significance}
        % \begin{itemize}
        %     \item By applying the chain rule, we systematically compute the impact of each weight on the overall error, enabling efficient optimization of the neural network.
        %     \item This process is repeated iteratively across all layers and weights to minimize the loss function and improve the model's predictions.
        % \end{itemize}
        % \end{block}
        
        \end{frame}

 	
\end{document}